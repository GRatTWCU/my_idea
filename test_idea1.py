#!/usr/bin/env python3
"""
test_idea1.py - Social-LSTM IDEA1ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã‚ãšã«ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèªã‚’è¡Œã†
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import sys
import argparse
import pickle
import time
from typing import Dict, List, Tuple, Optional

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append('.')

def create_dummy_dataloader_data(batch_size=3, seq_length=8, pred_length=12, num_pedestrians=5):
    """
    ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦DataLoaderã®å‹•ä½œã‚’æ¨¡æ“¬
    """
    print("ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    
    # ãƒ€ãƒŸãƒ¼ã®è»Œè·¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    x_batch = []
    y_batch = []
    d_batch = []
    numPedsList_batch = []
    PedsList_batch = []
    target_ids = []
    
    for batch_idx in range(batch_size):
        # å„ãƒãƒƒãƒã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
        x_seq = []
        y_seq = []
        numPeds_seq = []
        pedsList_seq = []
        
        for t in range(seq_length):
            # æ™‚åˆ»tã§ã®æ­©è¡Œè€…ãƒ‡ãƒ¼ã‚¿
            num_peds_at_t = np.random.randint(2, num_pedestrians + 1)
            frame_data = []
            peds_list = []
            
            for ped_id in range(num_peds_at_t):
                # ãƒ©ãƒ³ãƒ€ãƒ ãªä½ç½®ç”Ÿæˆï¼ˆãƒªã‚¢ãƒ«ãªè»Œè·¡ã£ã½ãï¼‰
                base_x = 50 + ped_id * 20 + t * 2 + np.random.normal(0, 1)
                base_y = 100 + ped_id * 15 + t * 1.5 + np.random.normal(0, 1)
                
                frame_data.append([ped_id, base_x, base_y])
                peds_list.append(ped_id)
            
            x_seq.append(np.array(frame_data) if frame_data else np.array([]).reshape(0, 3))
            numPeds_seq.append(num_peds_at_t)
            pedsList_seq.append(peds_list)
        
        # äºˆæ¸¬ç”¨ã®yç³»åˆ—ï¼ˆxç³»åˆ—ã®ç¶šãï¼‰
        for t in range(pred_length):
            num_peds_at_t = numPeds_seq[-1]  # æœ€å¾Œã®è¦³æ¸¬ã¨åŒã˜æ­©è¡Œè€…æ•°
            frame_data = []
            
            for ped_id in range(num_peds_at_t):
                # ç¶šãã®è»Œè·¡ç”Ÿæˆ
                prev_x = x_seq[-1][ped_id][1] if len(x_seq[-1]) > ped_id else 50
                prev_y = x_seq[-1][ped_id][2] if len(x_seq[-1]) > ped_id else 100
                
                next_x = prev_x + 2 + np.random.normal(0, 0.5)
                next_y = prev_y + 1.5 + np.random.normal(0, 0.5)
                
                frame_data.append([ped_id, next_x, next_y])
            
            y_seq.append(np.array(frame_data) if frame_data else np.array([]).reshape(0, 3))
        
        x_batch.append(x_seq)
        y_batch.append(y_seq)
        d_batch.append(0)  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        numPedsList_batch.append(numPeds_seq)
        PedsList_batch.append(pedsList_seq)
        target_ids.append(0)  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆID
    
    return x_batch, y_batch, d_batch, numPedsList_batch, PedsList_batch, target_ids

class MockDataLoader:
    """DataLoaderã®å‹•ä½œã‚’æ¨¡æ“¬ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, batch_size=3, seq_length=8, pred_length=12, num_pedestrians=5):
        self.batch_size = batch_size
        self.seq_length = seq_length
        self.pred_length = pred_length
        self.num_pedestrians = num_pedestrians
        self.num_batches = 2  # ãƒ†ã‚¹ãƒˆç”¨ã«2ãƒãƒƒãƒ
        self.valid_num_batches = 1
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        self._generate_dummy_data()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¬¡å…ƒï¼ˆBIWIï¼‰
        self.dataset_dimensions = {'biwi': [720, 576]}
        
        print(f"MockDataLoaderä½œæˆå®Œäº†")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
        print(f"  ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {seq_length}")
        print(f"  äºˆæ¸¬é•·: {pred_length}")
        print(f"  æœ€å¤§æ­©è¡Œè€…æ•°: {num_pedestrians}")
    
    def _generate_dummy_data(self):
        """ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ç”Ÿæˆ"""
        self.train_data = []
        self.valid_data = []
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿
        for _ in range(self.num_batches):
            batch_data = create_dummy_dataloader_data(
                self.batch_size, self.seq_length, self.pred_length, self.num_pedestrians
            )
            self.train_data.append(batch_data)
        
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
        for _ in range(self.valid_num_batches):
            batch_data = create_dummy_dataloader_data(
                self.batch_size, self.seq_length, self.pred_length, self.num_pedestrians
            )
            self.valid_data.append(batch_data)
        
        self.current_batch = 0
        self.current_valid_batch = 0
    
    def next_batch(self):
        """æ¬¡ã®è¨“ç·´ãƒãƒƒãƒã‚’å–å¾—"""
        if self.current_batch >= len(self.train_data):
            self.current_batch = 0
        
        batch_data = self.train_data[self.current_batch]
        self.current_batch += 1
        return batch_data
    
    def next_valid_batch(self):
        """æ¬¡ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒã‚’å–å¾—"""
        if self.current_valid_batch >= len(self.valid_data):
            self.current_valid_batch = 0
        
        batch_data = self.valid_data[self.current_valid_batch]
        self.current_valid_batch += 1
        return batch_data
    
    def reset_batch_pointer(self, valid=False):
        """ãƒãƒƒãƒãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        if valid:
            self.current_valid_batch = 0
        else:
            self.current_batch = 0
    
    def convert_proper_array(self, x_seq, num_pedlist, pedlist):
        """DataLoaderã¨åŒã˜å½¢å¼ã§é…åˆ—å¤‰æ›"""
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã‚’å–å¾—
        unique_ids = []
        for peds_in_frame in pedlist:
            unique_ids.extend(peds_in_frame)
        unique_ids = list(set(unique_ids))
        
        if not unique_ids:
            # æ­©è¡Œè€…ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            seq_data = torch.zeros(self.seq_length, 1, 2)
            lookup_table = {}
        else:
            # ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            lookup_table = {ped_id: idx for idx, ped_id in enumerate(unique_ids)}
            
            # é…åˆ—ä½œæˆ
            seq_data = torch.zeros(self.seq_length, len(unique_ids), 2)
            
            for t, frame_data in enumerate(x_seq):
                if len(frame_data) > 0:
                    for ped_data in frame_data:
                        ped_id = int(ped_data[0])
                        if ped_id in lookup_table:
                            idx = lookup_table[ped_id]
                            seq_data[t, idx, 0] = ped_data[1]  # xåº§æ¨™
                            seq_data[t, idx, 1] = ped_data[2]  # yåº§æ¨™
        
        return seq_data, lookup_table
    
    def get_directory_name_with_pointer(self, dataset_idx):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’è¿”ã™"""
        return 'biwi'
    
    def get_dataset_dimension(self, dataset_name):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¬¡å…ƒã‚’è¿”ã™"""
        return self.dataset_dimensions.get(dataset_name, [720, 576])

def test_model_creation():
    """ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*50)
    
    try:
        from model import TwoStageTrajectoryPredictor
        
        # å°ã•ãªãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = TwoStageTrajectoryPredictor(
            input_dim=2,
            hidden_dim=32,
            output_dim=2,
            seq_len=8,
            pred_len=12,
            num_pedestrians=5,
            dropout=0.1
        )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°è¨ˆç®—
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸ")
        print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"  è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
        
        return model
        
    except Exception as e:
        print(f"âœ— ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_forward_pass(model):
    """é †ä¼æ’­ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("é †ä¼æ’­ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*50)
    
    try:
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        batch_size = 2
        seq_len = 8
        pred_len = 12
        num_peds = 5
        
        input_traj = torch.randn(batch_size, seq_len, num_peds, 2)
        obstacle_map = torch.randn(batch_size, 2)
        
        print(f"å…¥åŠ›è»Œè·¡å½¢çŠ¶: {input_traj.shape}")
        print(f"éšœå®³ç‰©ãƒãƒƒãƒ—å½¢çŠ¶: {obstacle_map.shape}")
        
        # é †ä¼æ’­å®Ÿè¡Œ
        model.eval()
        with torch.no_grad():
            final_pred, stage1_pred, contrast_loss = model(
                input_traj, obstacle_map, training=False
            )
        
        print(f"âœ“ é †ä¼æ’­æˆåŠŸ")
        print(f"  æœ€çµ‚äºˆæ¸¬å½¢çŠ¶: {final_pred.shape}")
        print(f"  ç¬¬1æ®µéšäºˆæ¸¬å½¢çŠ¶: {stage1_pred.shape}")
        print(f"  ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæå¤±: {contrast_loss.item():.6f}")
        
        # æœŸå¾…ã•ã‚Œã‚‹å½¢çŠ¶ãƒã‚§ãƒƒã‚¯
        expected_shape = (batch_size, pred_len, num_peds, 2)
        if final_pred.shape == expected_shape:
            print(f"âœ“ å‡ºåŠ›å½¢çŠ¶ãŒæ­£ã—ã„: {expected_shape}")
        else:
            print(f"âœ— å‡ºåŠ›å½¢çŠ¶ãŒä¸æ­£: æœŸå¾… {expected_shape}, å®Ÿéš› {final_pred.shape}")
            return False
        
        return True
        
    except Exception as e:
        print(f"âœ— é †ä¼æ’­ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_training_step_with_mock_data(model):
    """MockDataLoaderã‚’ä½¿ã£ãŸè¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("MockDataLoaderè¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*50)
    
    try:
        # MockDataLoaderä½œæˆ
        dataloader = MockDataLoader(
            batch_size=2, seq_length=8, pred_length=12, num_pedestrians=5
        )
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        # 1å›ã®è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
        x, y, d, numPedsList, PedsList, target_ids = dataloader.next_batch()
        
        print(f"ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ:")
        print(f"  x length: {len(x)}")
        print(f"  y length: {len(y)}")
        print(f"  d length: {len(d)}")
        
        # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã¨ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
        model.train()
        total_loss = 0
        valid_sequences = 0
        
        for sequence in range(len(x)):
            x_seq, y_seq = x[sequence], y[sequence]
            d_seq = d[sequence]
            
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            x_dense, lookup_seq = dataloader.convert_proper_array(
                x_seq, numPedsList[sequence], PedsList[sequence]
            )
            y_dense, _ = dataloader.convert_proper_array(
                y_seq, numPedsList[sequence], PedsList[sequence]
            )
            
            if x_dense.shape[1] == 0:
                continue
            
            print(f"  ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ {sequence}: x_denseå½¢çŠ¶ {x_dense.shape}, y_denseå½¢çŠ¶ {y_dense.shape}")
            
            # ãƒãƒƒãƒå½¢å¼ã«å¤‰æ›
            x_batch = x_dense.unsqueeze(0)  # (1, seq_len, num_peds, 2)
            y_batch = y_dense.unsqueeze(0)
            
            # ç’°å¢ƒãƒãƒƒãƒ—ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
            dataset_dims = dataloader.get_dataset_dimension('biwi')
            last_pos = x_dense[-1, :, :].mean(dim=0).unsqueeze(0)  # é‡å¿ƒ
            obstacle_map = torch.tensor([[last_pos[0]/dataset_dims[0], last_pos[1]/dataset_dims[1]]])
            
            # äºˆæ¸¬å®Ÿè¡Œ
            final_pred, stage1_pred, contrast_loss = model(
                x_batch, obstacle_map, training=True
            )
            
            # æå¤±è¨ˆç®—
            final_loss = F.mse_loss(final_pred, y_batch)
            stage1_loss = F.mse_loss(stage1_pred, y_batch)
            batch_loss = final_loss + 0.3 * stage1_loss + 0.1 * contrast_loss
            
            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            optimizer.zero_grad()
            batch_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)
            optimizer.step()
            
            total_loss += batch_loss.item()
            valid_sequences += 1
            
            print(f"    æœ€çµ‚æå¤±: {final_loss.item():.6f}")
            print(f"    ç¬¬1æ®µéšæå¤±: {stage1_loss.item():.6f}")
            print(f"    ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæå¤±: {contrast_loss.item():.6f}")
            print(f"    ç·æå¤±: {batch_loss.item():.6f}")
        
        avg_loss = total_loss / max(valid_sequences, 1)
        print(f"âœ“ è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æˆåŠŸ")
        print(f"  å¹³å‡æå¤±: {avg_loss:.6f}")
        print(f"  å‡¦ç†ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {valid_sequences}")
        
        return True
        
    except Exception as e:
        print(f"âœ— è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_evaluation_metrics(model):
    """è©•ä¾¡æŒ‡æ¨™ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("è©•ä¾¡æŒ‡æ¨™ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*50)
    
    try:
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        batch_size = 3
        pred_len = 12
        num_peds = 4
        
        # å®Ÿéš›ã®äºˆæ¸¬ã¨çœŸå€¤ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        predictions = torch.randn(batch_size, pred_len, num_peds, 2)
        ground_truth = torch.randn(batch_size, pred_len, num_peds, 2)
        
        # ADE (Average Displacement Error) è¨ˆç®—
        displacement_errors = torch.norm(predictions - ground_truth, dim=-1)
        ade = displacement_errors.mean().item()
        
        # FDE (Final Displacement Error) è¨ˆç®—
        final_displacement = torch.norm(predictions[:, -1] - ground_truth[:, -1], dim=-1)
        fde = final_displacement.mean().item()
        
        print(f"âœ“ è©•ä¾¡æŒ‡æ¨™è¨ˆç®—æˆåŠŸ")
        print(f"  ADE: {ade:.6f}")
        print(f"  FDE: {fde:.6f}")
        
        # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã§ã®è©•ä¾¡
        model.eval()
        with torch.no_grad():
            input_traj = torch.randn(batch_size, 8, num_peds, 2)
            obstacle_map = torch.randn(batch_size, 2)
            
            final_pred, _, _ = model(input_traj, obstacle_map, training=False)
            
            # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã§ã®è©•ä¾¡æŒ‡æ¨™
            model_ade = torch.norm(final_pred - ground_truth, dim=-1).mean().item()
            model_fde = torch.norm(final_pred[:, -1] - ground_truth[:, -1], dim=-1).mean().item()
            
            print(f"  ãƒ¢ãƒ‡ãƒ«å‡ºåŠ› ADE: {model_ade:.6f}")
            print(f"  ãƒ¢ãƒ‡ãƒ«å‡ºåŠ› FDE: {model_fde:.6f}")
        
        return True
        
    except Exception as e:
        print(f"âœ— è©•ä¾¡æŒ‡æ¨™ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_components():
    """å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "="*50)
    print("å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*50)
    
    try:
        from model import (
            EnvironmentalAttentionModule,
            SingularTrajectoryPredictor,
            SocialSTGCNN
        )
        
        # 1. ECAM ãƒ†ã‚¹ãƒˆ
        print("1. EnvironmentalAttentionModule ãƒ†ã‚¹ãƒˆ")
        ecam = EnvironmentalAttentionModule(embedding_dim=32, env_dim=16, dropout=0.1)
        traj = torch.randn(2, 6, 2)
        obstacle = torch.randn(2, 2)
        attended_traj, contrast_feat = ecam(traj, obstacle)
        print(f"   âœ“ ECAMå‹•ä½œç¢ºèª - å‡ºåŠ›å½¢çŠ¶: {attended_traj.shape}")
        
        # 2. ç¬¬1æ®µéšäºˆæ¸¬å™¨ãƒ†ã‚¹ãƒˆ
        print("2. SingularTrajectoryPredictor ãƒ†ã‚¹ãƒˆ")
        predictor = SingularTrajectoryPredictor(
            input_dim=2, hidden_dim=32, output_dim=2,
            seq_len=6, pred_len=8, num_layers=1, dropout=0.1
        )
        input_traj = torch.randn(2, 6, 2)
        pred_traj, contrast_feat = predictor(input_traj, obstacle, training=True)
        print(f"   âœ“ ç¬¬1æ®µéšäºˆæ¸¬å™¨å‹•ä½œç¢ºèª - å‡ºåŠ›å½¢çŠ¶: {pred_traj.shape}")
        
        # 3. Social-STGCNN ãƒ†ã‚¹ãƒˆ
        print("3. SocialSTGCNN ãƒ†ã‚¹ãƒˆ")
        stgcnn = SocialSTGCNN(
            input_dim=2, hidden_dim=32, output_dim=2,
            seq_len=6, pred_len=8, num_nodes=4, num_blocks=2, dropout=0.1
        )
        input_trajs = torch.randn(2, 6, 4, 2)
        pred_trajs = stgcnn(input_trajs)
        print(f"   âœ“ Social-STGCNNå‹•ä½œç¢ºèª - å‡ºåŠ›å½¢çŠ¶: {pred_trajs.shape}")
        
        print("âœ“ å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("Social-LSTM IDEA1 ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*60)
    
    # ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
    print(f"PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³: {torch.__version__}")
    
    # ãƒ†ã‚¹ãƒˆãƒªã‚¹ãƒˆ
    tests = [
        ("å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ", test_model_components),
        ("ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ", test_model_creation),
    ]
    
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    model = None
    for test_name, test_func in tests:
        print(f"\n{test_name} å®Ÿè¡Œä¸­...")
        try:
            if test_name == "ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ":
                model = test_func()
                success = model is not None
            else:
                success = test_func()
                
            if success:
                print(f"âœ“ {test_name} æˆåŠŸ")
            else:
                print(f"âœ— {test_name} å¤±æ•—")
                return False
        except Exception as e:
            print(f"âœ— {test_name} ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸè©³ç´°ãƒ†ã‚¹ãƒˆ
    if model is not None:
        detailed_tests = [
            ("é †ä¼æ’­ãƒ†ã‚¹ãƒˆ", lambda: test_forward_pass(model)),
            ("MockDataLoaderè¨“ç·´ãƒ†ã‚¹ãƒˆ", lambda: test_training_step_with_mock_data(model)),
            ("è©•ä¾¡æŒ‡æ¨™ãƒ†ã‚¹ãƒˆ", lambda: test_evaluation_metrics(model)),
        ]
        
        for test_name, test_func in detailed_tests:
            print(f"\n{test_name} å®Ÿè¡Œä¸­...")
            try:
                success = test_func()
                if success:
                    print(f"âœ“ {test_name} æˆåŠŸ")
                else:
                    print(f"âœ— {test_name} å¤±æ•—")
            except Exception as e:
                print(f"âœ— {test_name} ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                traceback.print_exc()
    
    # æœ€çµ‚çµæœ
    print("\n" + "="*60)
    print("ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("="*60)
    print("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§train_idea1.pyã‚’å®Ÿè¡Œã§ãã¾ã™:")
    print()
    print("# è»½é‡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("python train_idea1.py --batch_size 2 --seq_length 8 --pred_length 8 --num_epochs 3 --hidden_dim 32 --max_pedestrians 5")
    print()
    print("# æœ¬æ ¼å®Ÿè¡Œï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚‹å ´åˆï¼‰")
    print("python train_idea1.py --batch_size 5 --seq_length 20 --pred_length 12 --num_epochs 30 --use_cuda")
    print("="*60)
    
    return True

if __name__ == "__main__":
    main()